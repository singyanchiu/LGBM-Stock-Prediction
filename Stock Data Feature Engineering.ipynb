{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Today's date: 2020-04-23\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy import stats\n",
    "import lightgbm as lgb\n",
    "import warnings\n",
    "import os.path\n",
    "import info\n",
    "#import lightgbm as lgb\n",
    "from utils import *\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "today = datetime.today()\n",
    "print(\"Today's date:\", today.strftime(\"%Y-%m-%d\"))\n",
    "\n",
    "path_pc = 'C:/Users/admin/Desktop/AI Plan/Finance with AI/Notebooks/'\n",
    "\n",
    "count = 0\n",
    "day = today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "symbols_all50 = ['0001.HK','0002.HK','0003.HK','0005.HK','0006.HK','0011.HK','0012.HK', '0016.HK','0017.HK','0019.HK','0027.HK','0066.HK',\n",
    " '0083.HK', '0101.HK','0151.HK','0175.HK','0267.HK','0288.HK','0386.HK','0388.HK','0669.HK','0688.HK','0700.HK','0762.HK','0823.HK',\n",
    " '0857.HK','0883.HK','0939.HK','0941.HK','1038.HK','1044.HK','1088.HK','1093.HK','1109.HK','1113.HK','1177.HK','1299.HK','1398.HK',\n",
    " '1928.HK','1997.HK','2007.HK','2018.HK','2313.HK','2318.HK','2319.HK','2382.HK','2388.HK','2628.HK','3328.HK','3988.HK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying  outcomes_2020-04-23.csv\n",
      "Loading file:  outcomes_2020-04-23.csv\n"
     ]
    }
   ],
   "source": [
    "outcomes_new = load_latest(today, 'outcomes_', path_pc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'outcomes_new_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0063d0423a4b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutcomes_new_features\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'outcomes_new_features' is not defined"
     ]
    }
   ],
   "source": [
    "list(outcomes_new_features.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wwma(values, n):\n",
    "    \"\"\"\n",
    "     J. Welles Wilder's EMA \n",
    "    \"\"\"\n",
    "    return values.ewm(alpha=1/n, adjust=False).mean()\n",
    "\n",
    "def atr(df, symbol, n=14):\n",
    "    df_symbol = df.loc[df.index.get_level_values('symbol') == symbol]\n",
    "    high = df_symbol['high']\n",
    "    low = df_symbol['low']\n",
    "    close = df_symbol['close']\n",
    "    df_symbol['tr0'] = abs(high - low)\n",
    "    df_symbol['tr1'] = abs(high - close.shift(1))\n",
    "    df_symbol['tr2'] = abs(low - close.shift(1))\n",
    "    tr = df_symbol[['tr0', 'tr1', 'tr2']].max(axis=1)\n",
    "    atr = wwma(tr, n)\n",
    "    return atr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate atr10, 14, 20, 100\n",
    "for symbol in sorted(list(info.board_lots.keys())):\n",
    "    print(\"Calculating atr for \", symbol)\n",
    "    ts_atr14 = atr(outcomes_new, symbol, n=14)\n",
    "    ts_atr10 = atr(outcomes_new, symbol, n=10)\n",
    "    ts_atr20 = atr(outcomes_new, symbol, n=20)\n",
    "    ts_atr100 = atr(outcomes_new, symbol, n=100)\n",
    "    outcomes_new = outcomes_new.combine_first(ts_atr14.to_frame().rename(columns={0:'atr14'}))\n",
    "    outcomes_new = outcomes_new.combine_first(ts_atr10.to_frame().rename(columns={0:'atr10'}))\n",
    "    outcomes_new = outcomes_new.combine_first(ts_atr20.to_frame().rename(columns={0:'atr20'}))\n",
    "    outcomes_new = outcomes_new.combine_first(ts_atr100.to_frame().rename(columns={0:'atr100'}))\n",
    "    \n",
    "#Calculate ATR ratio\n",
    "outcomes_new['atr10/atr100'] = outcomes_new['atr10']/outcomes_new['atr100']\n",
    "outcomes_new['atr10/atr20'] = outcomes_new['atr10']/outcomes_new['atr20']\n",
    "\n",
    "#Calculate Delta ATR\n",
    "delta10 = lambda x: x-x.shift(10)\n",
    "delta3 = lambda x: x-x.shift(3)\n",
    "\n",
    "outcomes_new['delta_atr10/atr100_10'] = outcomes_new['atr10/atr100'].groupby(level='symbol').apply(delta10)\n",
    "outcomes_new['delta_atr10/atr100_3'] = outcomes_new['atr10/atr100'].groupby(level='symbol').apply(delta3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_5 = lambda x: x.rolling(window=5, min_periods=1).std()\n",
    "std_10 = lambda x: x.rolling(window=10, min_periods=1).std()\n",
    "std_25 = lambda x: x.rolling(window=25, min_periods=1).std()\n",
    "std_100 = lambda x: x.rolling(window=100, min_periods=1).std()\n",
    "outcomes_new['volatility5'] = outcomes_new.groupby(level='symbol').close.apply(std_5)\n",
    "outcomes_new['volatility10'] = outcomes_new.groupby(level='symbol').close.apply(std_10)\n",
    "outcomes_new['volatility25'] = outcomes_new.groupby(level='symbol').close.apply(std_25)\n",
    "outcomes_new['volatility100'] = outcomes_new.groupby(level='symbol').close.apply(std_100)\n",
    "outcomes_new['volatility5_ratio'] = outcomes_new.volatility5/outcomes_new.close\n",
    "outcomes_new['volatility10_ratio'] = outcomes_new.volatility10/outcomes_new.close\n",
    "outcomes_new['volatility25_ratio'] = outcomes_new.volatility25/outcomes_new.close\n",
    "outcomes_new['volatility100_ratio'] = outcomes_new.volatility100/outcomes_new.close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes_new= outcomes_new.drop(axis=1, labels=['momentum'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum_windows = [(5,3),(10,7),(25,20),(50,40),(100,70)]\n",
    "#minimum_momentums = [3,7,20,40,70]\n",
    "\n",
    "print(\"Calculating momentums...\")\n",
    "for (momentum_window, minimum_momentum) in momentum_windows:\n",
    "    for symbol in symbols_all50:\n",
    "        print(\"Calculating for \" + symbol)\n",
    "        df_mom = outcomes_new.copy()\n",
    "        df_mom['momentum'+'_'+str(momentum_window)] = df_mom.loc[df_mom.index.get_level_values('symbol') == symbol].close.rolling(momentum_window, min_periods = minimum_momentum).apply(momentum_score)\n",
    "        outcomes_new = outcomes_new.combine_first(df_mom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_50 = lambda x: x.ewm(span=50, min_periods=1).mean()\n",
    "ema_80 = lambda x: x.ewm(span=80, min_periods=1).mean()\n",
    "ema_40 = lambda x: x.ewm(span=40, min_periods=1).mean()\n",
    "\n",
    "outcomes_new['ema40']=outcomes_new.close.groupby(level='symbol').apply(ema_40) #TEMP feature only\n",
    "outcomes_new['ema80']=outcomes_new.close.groupby(level='symbol').apply(ema_80) #TEMP feature only\n",
    "outcomes_new['bull']=outcomes_new['ema40']>outcomes_new['ema80']\n",
    "outcomes_new['bull_ratio']=outcomes_new['ema40']/outcomes_new['ema80']-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_50 = lambda x: x.rolling(50, min_periods=1).max()\n",
    "outcomes_new['50d_high']=outcomes_new.close.groupby(level='symbol').apply(max_50)  #TEMP feature only\n",
    "outcomes_new['close>50d_high']=outcomes_new['close']>=outcomes_new['50d_high']\n",
    "outcomes_new['50d_high_volume']=outcomes_new.volume.groupby(level='symbol').apply(max_50)\n",
    "outcomes_new['volume_vs_50d_high']=outcomes_new['volume']/outcomes_new['50d_high_volume']\n",
    "outcomes_new['close_vs_50d_high']=outcomes_new['close']/outcomes_new['50d_high']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['volume', 'log volume']\n",
    "for col in cols:\n",
    "    for i in range(1,6):\n",
    "        pct_chg = lambda x: x.pct_change(i)\n",
    "        outcomes_new[col+'_pct_chg_'+str(i)] =outcomes_new.groupby(level='symbol')[col].apply(pct_chg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zscore_50 = lambda x: (x - x.rolling(window=50, min_periods=1).mean())/x.rolling(window=50, min_periods=1).std()\n",
    "cols = [\n",
    "'log volume',\n",
    "'volume_pct_chg_1',\n",
    "'volume_pct_chg_2',\n",
    "'volume_pct_chg_3',\n",
    "'volume_pct_chg_4',\n",
    "'volume_pct_chg_5',\n",
    "'past_return_1',\n",
    "'past_return_2',\n",
    "'past_return_3',\n",
    "'past_return_4',\n",
    "'past_return_5',\n",
    "'past_return_10',\n",
    "'volatility50',\n",
    "'delta_atr10/atr100_3',\n",
    "'delta_atr10/atr100_10',\n",
    "'atr10',\n",
    "'atr14',\n",
    "'atr20',\n",
    "'atr100',\n",
    "'atr10/atr100',\n",
    "'atr10/atr20',\n",
    "'log volume_pct_chg_1',\n",
    "'log volume_pct_chg_2',\n",
    "'log volume_pct_chg_3',\n",
    "'log volume_pct_chg_4',\n",
    "'log volume_pct_chg_5']\n",
    "for col in cols:\n",
    "    outcomes_new[col+'_scaled50'] =outcomes_new.groupby(level='symbol')[col].apply(zscore_50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating Market Meanness Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for symbol in sorted(list(info.board_lots.keys())):\n",
    "    print(\"Calculating mmi for\", symbol)\n",
    "    df_mom = outcomes_new.copy()\n",
    "    df_mom['mmi50'] = df_mom.loc[df_mom.index.get_level_values('symbol') == symbol].close.rolling(50, min_periods = 2).apply(mmi)\n",
    "    outcomes_new = outcomes_new.combine_first(df_mom)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate dynamic targets\n",
    "### calculate exponential moving average of standard deviation (volatility) of past return 5 - vol_pst_ret5\n",
    "### for each vol_pst_ret5, look 5 days ahead. Cache current close and vol_pst_ret5. Initialize target = 0.\n",
    "For each day:\n",
    "1) Compare current close and that day's High (get signed difference), if return is more than vol_pst_ret5, current target = 1, break 5-day loop, skip to next vol_pst_ret5\n",
    "2) Compare current close and that day's Low (get signed difference), if loss is more than vol_pst_ret5, current target = -1, break 5-day loop, skip to next vol_pst_ret5\n",
    "\n",
    "### April 3: V2 of horizontal barriers - daily return\n",
    "1) caculate exponentially weighted moving standard deviation  of daily return\n",
    "2) set target to about 2.2 times of it\n",
    "\n",
    "### April 3: V3of horizontal barriers - daily price change\n",
    "1) caculate exponentially weighted moving standard deviation  of daily price change\n",
    "2) May not make a big difference from V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_std50 = lambda x: x.ewm(span=50, min_periods=20).std()\n",
    "outcomes_new['past_return_1_ema_std50'] = outcomes_new.groupby(level='symbol').past_return_1.apply(ema_std50)\n",
    "\n",
    "price_chg_1 = lambda x: x-x.shift(1)\n",
    "outcomes_new['price_chg_1'] = outcomes_new.groupby(level='symbol').close.apply(price_chg_1)\n",
    "outcomes_new['price_chg_1_ema_std50'] = outcomes_new.groupby(level='symbol').price_chg_1.apply(ema_std50)\n",
    "outcomes_new['past_return_1_ema_std50*2.2'] = outcomes_new['past_return_1_ema_std50'] * 2.2\n",
    "outcomes_new['price_chg_1_ema_std50*2.2'] = outcomes_new['price_chg_1_ema_std50'] * 2.2/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_50 = lambda x: x.rolling(window=50, min_periods=20).std()\n",
    "\n",
    "outcomes_new['volume_std50'] = outcomes_new.groupby(level='symbol').volume.apply(std_50)\n",
    "outcomes_new['log volume_std50'] = outcomes_new.groupby(level='symbol')['log volume'].apply(std_50)\n",
    "outcomes_new['past_return_5_std50'] = outcomes_new.groupby(level='symbol').past_return_5.apply(std_50)\n",
    "outcomes_new['past_return_4_std50'] = outcomes_new.groupby(level='symbol').past_return_4.apply(std_50)\n",
    "outcomes_new['past_return_3_std50'] = outcomes_new.groupby(level='symbol').past_return_3.apply(std_50)\n",
    "outcomes_new['past_return_2_std50'] = outcomes_new.groupby(level='symbol').past_return_2.apply(std_50)\n",
    "outcomes_new['past_return_1_std50'] = outcomes_new.groupby(level='symbol').past_return_1.apply(std_50)\n",
    "outcomes_new['past_return_10_std50'] = outcomes_new.groupby(level='symbol').past_return_10.apply(std_50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes_new['target_upper'] = outcomes_new.close*(1+outcomes_new.past_return_5_std50)\n",
    "outcomes_new['target_lower'] = outcomes_new.close*(1-outcomes_new.past_return_5_std50)\n",
    "#outcomes_new[['close','target_lower','target_upper']][-50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outcomes_new['target_upper_v2'] = outcomes_new.close*(1+outcomes_new['past_return_1_ema_std50*2.2'])\n",
    "outcomes_new['target_lower_v2'] = outcomes_new.close*(1-outcomes_new['past_return_1_ema_std50*2.2'])\n",
    "#outcomes_new[['close','target_lower_v2','target_upper_v2']][-50:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating target V1 (std50 of 5-day return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "out_new = outcomes_new.copy()\n",
    "for symbol in symbols_all50:\n",
    "    symbol_df = outcomes_new.loc[outcomes_new.index.get_level_values('symbol')==symbol]\n",
    "    print('working on ', symbol)\n",
    "    symbol_df['label'] = float(\"NaN\")\n",
    "    for i, row in symbol_df.iterrows():\n",
    "        n = symbol_df.index.get_loc(i)\n",
    "        j = 1\n",
    "        #print('n = ', n, ' ', row['close'], ' ', row['target_lower'], ' ', row['target_upper'])\n",
    "        while len(symbol_df)>n+j and j <= 5:\n",
    "            if symbol_df.ix[n+j].high > row['target_upper']:\n",
    "                symbol_df.ix[i,'label'] = 1\n",
    "                break\n",
    "            elif symbol_df.ix[n+j].low < row['target_lower']:\n",
    "                symbol_df.ix[i,'label'] = -1\n",
    "                break\n",
    "            elif j == 5:\n",
    "                symbol_df.ix[i,'label'] = 0\n",
    "            #print('n+j = ', n+j, ' ', symbol_df.ix[n+j].high, ' ', symbol_df.ix[n+j].low)\n",
    "            j += 1\n",
    "    out_new = out_new.combine_first(symbol_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating target V2 (2.2 * emstd50 of daily return)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for symbol in symbols_all50:\n",
    "    symbol_df = out_new.loc[out_new.index.get_level_values('symbol')==symbol]\n",
    "    print('working on ', symbol)\n",
    "    symbol_df['label_v2'] = float(\"NaN\")\n",
    "    for i, row in symbol_df.iterrows():\n",
    "        n = symbol_df.index.get_loc(i)\n",
    "        j = 1\n",
    "        #print('n = ', n, ' ', row['close'], ' ', row['target_lower'], ' ', row['target_upper'])\n",
    "        while len(symbol_df)>n+j and j <= 5:\n",
    "            if symbol_df.ix[n+j].high > row['target_upper_v2']:\n",
    "                symbol_df.ix[i,'label_v2'] = 1\n",
    "                break\n",
    "            elif symbol_df.ix[n+j].low < row['target_lower_v2']:\n",
    "                symbol_df.ix[i,'label_v2'] = -1\n",
    "                break\n",
    "            elif j == 5:\n",
    "                symbol_df.ix[i,'label_v2'] = 0\n",
    "            #print('n+j = ', n+j, ' ', symbol_df.ix[n+j].high, ' ', symbol_df.ix[n+j].low)\n",
    "            j += 1\n",
    "    out_new = out_new.combine_first(symbol_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New features ideas\n",
    "* Bull: Boolean - ema40>ema80\n",
    "* 50d_high: Boolean - if close is a 50 day high\n",
    "* drawdown: (close - 50d_max) < how many (std50 of close.diff())\n",
    "* bull pulldown: ema40>ema80 and (close - 20d_max) < -3* (std40 of close.diff())\n",
    "* Trend Strength: float - consistent increase in price and consistent increase in volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_date = sorted(list(set(outcomes_new.index.get_level_values('date'))))[-1]\n",
    "\n",
    "save_csv(out_new, path_pc, 'outcomes_new_features_'+last_date.strftime(\"%Y-%m-%d\")+'.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
